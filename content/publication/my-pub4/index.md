---
# Documentation: https://sourcethemes.com/academic/docs/managing-content/

title: "Estimating Policy Functions in Payments Systems using Deep Reinforcement Learning"
authors: ["admin", "Han Du", "Rodney Garratt", "Francisco Rivadeneyra", "Pablo Samuel Castro"]
date: 2020-01-20T14:11:55-05:00
doi: ""

# Schedule page publish date (NOT publication's date).
publishDate: 2019-12-15T14:11:55-05:00

# Publication type.
# Legend: 0 = Uncategorized; 1 = Conference paper; 2 = Journal article;
# 3 = Preprint / Working Paper; 4 = Report; 5 = Book; 6 = Book section;
# 7 = Thesis; 8 = Patent
publication_types: ["1"]

# Publication name and optional abbreviated publication name.
publication: ""
publication_short: ""

abstract: "This paper utilizes deep reinforcement learning to approximate the policy rules of banks participating in a high-value payments system. The objective of the agents is to learn (a) the optimal intraday payments decisions; and (b) the optimal initial liquidity choices. In a simplified two-agent setting, the agents learn the optimal intraday payments policy when unrestricted collateral is provided. For the initial liquidity choice problem, when using the optimal intraday payments policy, the agents learn to choose the initial liquidity that minimizes the cost of processing all payments. Our results show the applicability of DRL to estimate best-response functions in real-world strategic games."

# Summary. An optional shortened abstract.
summary: "This paper utilizes deep reinforcement learning to approximate the policy rules of banks participating in a high-value payments system. In a simplified two-agent setting, the agents learn the optimal intraday payments policy and optimal initial liquidity choice policy. Our results show the applicability of DRL to estimate best-response functions in real-world strategic games."

tags: []
categories: []
featured: false

# Custom links (optional).
#   Uncomment and edit lines below to show custom links.
# links:
# - name: Follow
#   url: https://twitter.com
#   icon_pack: fab
#   icon: twitter

url_pdf: https://6659afe2-a-62cb3a1a-s-sites.googlegroups.com/site/rivadeneyr/paper_neurips2019.pdf?attachauth=ANoY7coxjkyIzt1qdmGSMkbsR6XhCBI0OugGlLSPye-EhwKYSbHGASti6EmohihgiqCwB6RB1w8DqaCP5Oc6dDz8gq84fjtoodkgfo9FdcvVIfAjdyRi4eiY1oMMGt20CBWIytgfo58izixWV-7BRgUXvWPCuxHRK-sJ0Ou_gTx1C25k7ntVd5SlH2vmPxaj6rkJDjhdAp1c_WytjV_nk29y6dYxPoaWOA%3D%3D&attredirects=0
url_code:
url_dataset:
url_poster: 36x48_Neurips2019.pdf
url_project:
url_slides:
url_source:
url_video:

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ""
  focal_point: ""
  preview_only: false

# Associated Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `internal-project` references `content/project/internal-project/index.md`.
#   Otherwise, set `projects: []`.
projects: []

# Slides (optional).
#   Associate this publication with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides: "example"` references `content/slides/example/index.md`.
#   Otherwise, set `slides: ""`.
slides: ""
---
